{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Methods in Economics\n",
    "\n",
    "## Lecture 3 - Solving Systems of Linear Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last update: 2017-11-14 11:08:54.143196\n"
     ]
    }
   ],
   "source": [
    "# Author: Alex Schmitt (schmitt@ifo.de)\n",
    "\n",
    "import datetime\n",
    "print('Last update: ' + str(datetime.datetime.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import scipy.linalg\n",
    "\n",
    "import sys\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Lecture\n",
    "\n",
    "- [Review: Matrices](#matrix)\n",
    "- [Review: Span and Linear Independence](#span)\n",
    "- [Review: Nonsingular vs. Singular Matrix](#sing)\n",
    "- [Systems of Linear Equations](#sle)\n",
    "- [Solving Triangular Linear Systems](#trile)\n",
    "- [LU Factorization using Gaussian Elimination](#lufac)\n",
    "- [Ill-Conditioned Matrices](#ill)\n",
    "- [Sparse Matrices](#sparse)\n",
    "- [Iterative Methods](#iterative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='matrix'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $A$ be a m-by-n matrix:\n",
    "\\begin{equation}A =\n",
    "\\left[\n",
    "\\begin{array}{cccc}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
    "    a_{21} & a_{22} & \\cdots & a_{2n} \\\\\n",
    "    \\vdots & \\vdots &  & \\vdots \\\\\n",
    "    a_{m1} & a_{m2} & \\cdots & a_{mn}\n",
    "\\end{array}\n",
    "\\right]\\end{equation}\n",
    "\n",
    "A n-by-n matrix is called a *square* matrix of order $n$:\n",
    "\\begin{equation}A =\n",
    "\\left[\n",
    "\\begin{array}{cccc}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
    "    a_{21} & a_{22} & \\cdots & a_{2n} \\\\\n",
    "    \\vdots & \\vdots &  & \\vdots \\\\\n",
    "    a_{n1} & a_{n2} & \\cdots & a_{nn}\n",
    "\\end{array}\n",
    "\\right]\\end{equation}\n",
    "\n",
    "A matrix $D$ of order $n$ is *diagonal* if all its non-zero elements are on its diagonal (i.e. the entries $a_{ij}$ with $i = j$):\n",
    "\\begin{equation}D =\n",
    "\\left[\n",
    "\\begin{array}{cccc}\n",
    "    a_{11} & 0 & \\cdots & 0 \\\\\n",
    "    0 & a_{22} & \\cdots & 0 \\\\\n",
    "    \\vdots & \\vdots &  & \\vdots \\\\\n",
    "    0 & 0 & \\cdots & a_{nn}\n",
    "\\end{array}\n",
    "\\right]\\end{equation}\n",
    "\n",
    "A matrix $L$ of order $n$ is *lower triangular* if all its non-zero elements are either diagonal entries or *strictly lower triangular* entries (i.e. the entries $a_{ij}$ for which $i > j$):\n",
    "\\begin{equation}L =\n",
    "\\left[\n",
    "\\begin{array}{cccc}\n",
    "    a_{11} & 0 & \\cdots & 0 \\\\\n",
    "    a_{21} & a_{22} & \\cdots & 0 \\\\\n",
    "    \\vdots & \\vdots &  & \\vdots \\\\\n",
    "    a_{n1} & a_{n2} & \\cdots & a_{nn}\n",
    "\\end{array}\n",
    "\\right]\\end{equation}\n",
    "\n",
    "A matrix $U$ of order $n$ is *upper triangular* if all its non-zero elements are either diagonal entries or *strictly upper triangular* entries (i.e. the entries $a_{ij}$ for which $i < j$):\n",
    "\\begin{equation}U =\n",
    "\\left[\n",
    "\\begin{array}{cccc}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
    "    0 & a_{22} & \\cdots & a_{2n} \\\\\n",
    "    \\vdots & \\vdots &  & \\vdots \\\\\n",
    "    0 & 0 & \\cdots & a_{nn}\n",
    "\\end{array}\n",
    "\\right]\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices in Python\n",
    "\n",
    "In Python, matrices are best coded as *Numpy arrays*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  0 -1  2]\n",
      " [ 4  2 -1  4]\n",
      " [ 2 -2 -2  3]\n",
      " [-2  2  7 -3]]\n"
     ]
    }
   ],
   "source": [
    "## define matrix\n",
    "A = np.array([[2, 0, -1, 2],\n",
    "              [4, 2, -1, 4],\n",
    "              [2, -2, -2, 3],\n",
    "              [-2, 2, 7, -3]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "## get dimension of matrix\n",
    "print( A.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "## access elements by indices\n",
    "print(A[2,1])\n",
    "print(A[3,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the **transpose** $A'$ (or $A^T$) of matrix $A$ is formed by replacing $a_{ij}$ with $a_{ji}$ for every $i$ and $j$. If $A = A'$, the matrix is **symmetric**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  4  2 -2]\n",
      " [ 0  2 -2  2]\n",
      " [-1 -1 -2  7]\n",
      " [ 2  4  3 -3]]\n"
     ]
    }
   ],
   "source": [
    "## transpose matrix\n",
    "print(A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix addition and scalar multiplication are straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  0 -3  6]\n",
      " [12  6 -3 12]\n",
      " [ 6 -6 -6  9]\n",
      " [-6  6 21 -9]]\n"
     ]
    }
   ],
   "source": [
    "## scalar multiplication\n",
    "B = 3 * A\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8   0  -4   8]\n",
      " [ 16   8  -4  16]\n",
      " [  8  -8  -8  12]\n",
      " [ -8   8  28 -12]]\n"
     ]
    }
   ],
   "source": [
    "## matrix addition\n",
    "print( A + B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that multiplying two matrices $A$ and $B$, their product $A \\cdot B$ is formed by computing the *inner product* of the $i$th row of $A$ and the $j$th column of $B$, and assigning the result to the $i,j$th element. Matrix multiplication in Python is implemented using **@**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -6   18   42  -15]\n",
      " [  18   42   72    3]\n",
      " [ -42   18   75  -57]\n",
      " [  72  -48 -105  102]]\n"
     ]
    }
   ],
   "source": [
    "## matrix multiplication\n",
    "print( A @ B )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $AB$ and $BA$ are in general not the same. Also recall that multiplying a matrix $A$ with the identity matrix gives $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  0. -1.  2.]\n",
      " [ 4.  2. -1.  4.]\n",
      " [ 2. -2. -2.  3.]\n",
      " [-2.  2.  7. -3.]]\n"
     ]
    }
   ],
   "source": [
    "## with identity matrix\n",
    "print( np.eye(4) @ A )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When multiplying a matrix and a vector, make sure that the vector has the right dimension -\"flat\" arrays work either way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 21  4 11]\n",
      "[ 8  6 19  7]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "print(A @ x)\n",
    "print(x @ A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  6 19  7]]\n"
     ]
    }
   ],
   "source": [
    "## \"row vector\" (1-by-4)\n",
    "x = np.array([[1, 2, 3, 4]])\n",
    "print(x @ A) \n",
    "# print(A @ x) # this one won't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7]\n",
      " [21]\n",
      " [ 4]\n",
      " [11]]\n"
     ]
    }
   ],
   "source": [
    "## \"column vector\" (4-by-1)\n",
    "x = np.array([[1], [2], [3], [4]])\n",
    "print(A @ x) \n",
    "# print(x @ A) # this one won't work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Span and Linear Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='span'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For what follows below, it is useful to review the definition of linear independence of a collection of *vectors*. For this, we first need to define a *span*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Span\n",
    "\n",
    "Let $A$ be a collection of (column) vectors: $A = \\{ a_1, a_2, ..., a_n \\}$ where\n",
    "\\begin{equation}a_j =\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    a_{1j} \\\\\n",
    "    a_{2j}  \\\\\n",
    "    \\vdots \\\\\n",
    "    a_{mj} \n",
    "\\end{array}\n",
    "\\right] \\in \\mathbb{R}^m \\end{equation}\n",
    "\n",
    "$y \\in \\mathbb{R}^m$ is a **linear combination** of $A$ if \n",
    "\\begin{equation}\n",
    "    y = \\beta_1 a_1 + \\beta_2 a_2 + ... + \\beta_n a_n\n",
    "\\end{equation}\n",
    "for some (scalar) coefficients $\\beta_1, ..., \\beta_n$. \n",
    "\n",
    "The set of *all* linear combinations of $A$ is called the **span** of $A$. In other words, the span is the set of vectors that can be created by applying vector addition and scalar multiplications on the vectors in $A$.\n",
    "\n",
    "A special case is the set of *canonical vectors* $A = \\{ e_1, e_2, ..., e_n \\}$ where\n",
    "\n",
    "\\begin{equation}e_1 =\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    1 \\\\\n",
    "    0  \\\\\n",
    "    \\vdots \\\\\n",
    "    0 \n",
    "\\end{array}\n",
    "\\right],\\ e_2 =\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    0 \\\\\n",
    "    1  \\\\\n",
    "    \\vdots \\\\\n",
    "    0 \n",
    "\\end{array}\n",
    "\\right],\\ ...\\ \\in \\mathbb{R}^n \\end{equation}\n",
    "\n",
    "In this case, the span of $A$ is $\\mathbb{R}^n$: for any $y = (y_1, ..., y_n) \\in \\mathbb{R}^n$, we can write \n",
    "\n",
    "\\begin{equation}\n",
    "    y = y_1 e_1 + ... + y_n e_n.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Independence\n",
    "\n",
    "A collection of vectors $A = \\{ a_1, a_2, ..., a_n \\}$ in $\\mathbb{R}^m$ is \n",
    "- **linearly dependent** if some strict subset of $A$ has the same span as $A$\n",
    "- **linearly independent** if it is not linearly dependent\n",
    "In other words, a set of vectors is linearly independent if none of the vectors is redundant to the span.\n",
    "\n",
    "Moreover, the following is true for a linearly independent set of vectors $A$:\n",
    "1. no vector in $A$ can be formed as a linear combination of the other vectors\n",
    "2. if \n",
    "\\begin{equation} \n",
    "     \\beta_1 a_1 + \\beta_2 a_2 + ... + \\beta_n a_n = 0,\n",
    "\\end{equation}\n",
    "then $\\beta_1 = ... = \\beta_n = 0$.\n",
    "3. if\n",
    "\\begin{equation}\n",
    "    y = \\beta_1 a_1 + \\beta_2 a_2 + ... + \\beta_n a_n,\n",
    "\\end{equation}\n",
    "then no other coefficient sequence $\\gamma_1, ... , \\gamma_n$ will produce the same vector $y$.\n",
    "\n",
    "Linear independence is useful, since it implies that the set of vectors have a \"large span\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Nonsingular vs. singular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='sing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may recall from your linear algebra class, an important feature of a square matrix is whether or not it is *invertible*. An invertible matrix is also called *non-singular*, while a *singular* matrix cannot be inverted. \n",
    "\n",
    "This concept is closely related to linear independence of a collection of vectors. If the column vectors of a square matrix are linearly independent, it has **full column rank** (an analogous definition exists for the row vectors). A matrix $A$ is nonsingular if and only if it has full column rank.\n",
    "\n",
    "An alternative way to check whether a square matrix has an inverse is computing its **determinant** (I skip the definition here, but feel free to look it up if you don't remember). A matrix $A$ is nonsingular if and only if its determinant is not zero. In other words, a square matrix with linearly independent column vectors has a non-zero determinant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In Python\n",
    "\n",
    "Numpy's **linalg** module has functions to compute the determinant (**det()**) and the rank (**matrix_rank()**) of a matrix, as well as for inverting a matrix (**inv()**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-20.0\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, 0, -1, 2],\n",
    "              [4, 2, -1, 4],\n",
    "              [2, -2, -2, 3],\n",
    "              [-2, 2, 7, -3]])\n",
    "\n",
    "## compute the determinant of a matrix\n",
    "print( np.linalg.det(A) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "## compute the rank of a matrix\n",
    "print( np.linalg.matrix_rank(A) )\n",
    "print( np.linalg.matrix_rank(A.T) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.50000000e+00  -1.00000000e+00  -9.00000000e-01   1.00000000e-01]\n",
      " [ -1.00000000e+00   5.00000000e-01  -1.00000000e-01  -1.00000000e-01]\n",
      " [  0.00000000e+00   0.00000000e+00   2.00000000e-01   2.00000000e-01]\n",
      " [ -3.00000000e+00   1.00000000e+00   1.00000000e+00  -1.66533454e-17]]\n"
     ]
    }
   ],
   "source": [
    "## compute the inverse of a matrix\n",
    "print( np.linalg.inv(A) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are examples of a singular matrices. It is easy to see that in both cases, the column vectors are not linearly independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0, 0],\n",
    "              [1, 2]])\n",
    "\n",
    "print(np.linalg.det(X))\n",
    "print(np.linalg.matrix_rank(X))\n",
    "print(np.linalg.matrix_rank(X.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 0, 0],\n",
    "              [4, 0, 0],\n",
    "              [2, 3, 5]])\n",
    "\n",
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='sle'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System of Linear Equations\n",
    "\n",
    "A system of $m$ linear equations in $n$ unknowns $x_1, x_2, ... , x_n$ can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{array}{c}\n",
    "    a_{11} x_1 + \\cdots + a_{1n} x_n = b_1\\\\\n",
    "    \\vdots \\\\\n",
    "    a_{m1} x_1 + \\cdots + a_{mn} x_n = b_m\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "Let $x$ be a n-by-1 vector: $x = [x_1, x_2, ... , x_n]'$. Then, the system can be written in matrix form as $Ax = b$, since\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}A x\n",
    "=\n",
    "\\left[\n",
    "\\begin{array}{ccc}\n",
    "    a_{11} &  \\cdots & a_{1n} \\\\\n",
    "    \\vdots & \\vdots  & \\vdots \\\\\n",
    "    a_{m1} &  \\cdots & a_{mn}\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    x_{1}  \\\\\n",
    "    \\vdots  \\\\\n",
    "    x_{n}\n",
    "\\end{array}\n",
    "\\right] \n",
    "&=\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    a_{11} x_1 + \\cdots + a_{1n} x_n \\\\\n",
    "    \\vdots \\\\\n",
    "    a_{m1} x_1 + \\cdots + a_{mn} x_n\n",
    "\\end{array}\n",
    "\\right]\n",
    " = \n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    b_{1}  \\\\\n",
    "    \\vdots \\\\\n",
    "    b_{m} \n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{split}\n",
    "\\end{equation} \n",
    "\n",
    "The problem we face is to find $x \\in \\mathbb{R}^n$ that solves the expression above for a given $A$ and $b$. An important question is whether such an $x$ exists and whether it is unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before dealing with these question, why are SLEs (and being able to solve them) important? SLE arise in many computational economics problems, either directly or indirectly. \n",
    "- the prime example for a problem that directly involves a SLE is computing equilibrium prices and quantities in a model with multiples goods and linear demand and supply functions (see below);\n",
    "- solving SLEs is part of numerous algorithms when analyzing more complicated, non-linear problems; we will get to applications later in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Existence and Uniqueness\n",
    "\n",
    "\n",
    "To see what properties of $A$ give us existence and uniqueness, first note the following:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}A x\n",
    "=\n",
    "\\left[\n",
    "\\begin{array}{ccc}\n",
    "    a_{11} &  \\cdots & a_{1n} \\\\\n",
    "    \\vdots & \\vdots  & \\vdots \\\\\n",
    "    a_{m1} &  \\cdots & a_{mn}\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    x_{1}  \\\\\n",
    "    \\vdots  \\\\\n",
    "    x_{n}\n",
    "\\end{array}\n",
    "\\right] \n",
    "&=\n",
    "x_1\\left[\n",
    "\\begin{array}{c}\n",
    "    a_{11} \\\\\n",
    "    \\vdots \\\\\n",
    "    a_{m1} \n",
    "\\end{array}\n",
    "\\right]  +\n",
    "...\n",
    "+ x_n\\left[\n",
    "\\begin{array}{c}\n",
    "    a_{1n}  \\\\\n",
    "    \\vdots \\\\\n",
    "    a_{mn} \n",
    "\\end{array}\n",
    "\\right] \n",
    "\\end{split}\n",
    "\\end{equation} \n",
    "\n",
    "In words, $Ax$ can be written as a linear combination of the set of the column vectors in $A$, $\\{ a_1, a_2, ..., a_n \\}$ where\n",
    "\n",
    "\\begin{equation}a_j =\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    a_{1j} \\\\\n",
    "    a_{2j}  \\\\\n",
    "    \\vdots \\\\\n",
    "    a_{mj} \n",
    "\\end{array}\n",
    "\\right] \\in \\mathbb{R}^m \\end{equation}\n",
    "\n",
    "and where the coefficients are given by $x = (x_1, ... , x_n)$.\n",
    "\n",
    "Hence, for any $x \\in \\mathbb{R}^n$, $y = Ax$ is in the span of the column vectors of $A$. Put differently, if you define function $f$ such that $f(x) = Ax$, the range of $f$ is the span of the columns of $A$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Square Matrices\n",
    "\n",
    "Let $A$ be an n-by-n matrix. The system of linear equations has exactly as many unknown variables as the number of equation:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}A x\n",
    "=\n",
    "\\left[\n",
    "\\begin{array}{ccc}\n",
    "    a_{11} &  \\cdots & a_{1n} \\\\\n",
    "    \\vdots & \\vdots  & \\vdots \\\\\n",
    "    a_{n1} &  \\cdots & a_{nn}\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    x_{1}  \\\\\n",
    "    \\vdots  \\\\\n",
    "    x_{n}\n",
    "\\end{array}\n",
    "\\right] \n",
    " = \n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    b_{1}  \\\\\n",
    "    \\vdots \\\\\n",
    "    b_{n} \n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{split}\n",
    "\\end{equation} \n",
    "\n",
    "Consider the case that the column vectors in $A$ are linearly independent. Then, we know that:\n",
    "- since we need $n$ linearly independent vectors in $\\mathbb{R}^n$ to span $\\mathbb{R}^n$, the span of the columns of $A$ is $\\mathbb{R}^n$; hence, there must *exist* a vector $x$ such that $Ax = b$ for any $b \\in \\mathbb{R}^n$,\n",
    "- since no other vector $y$ will satisfy $Ay = b$ (see above), $x$ is *unique*\n",
    "\n",
    "To summarize, *if the columns of a square matrix $A$ are linearly independent ($A$ has full column rank), the system of linear equations $Ax = b$ has a unique solution*. Hence, we can compute the determinant or the column rank of $A$ in order to check for existence and uniqueness of a solution for a square SLE. \n",
    "\n",
    "Moreover, knowing that the inverse of $A$ exists, we can compute the solution to the SLE as\n",
    "\\begin{equation}\n",
    "    x = A^{-1} b\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Illustration in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xa493a55be0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFJCAYAAACsBZWNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhIEoYwERGRJAxhIiIiSRjCREREkvwPi8zBuHkh5YoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa498b8aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = np.array([[1, 1],\n",
    "              [2, 1]])\n",
    "b = np.array([3, 4])\n",
    "\n",
    "\n",
    "\n",
    "f1 =  lambda x: 3 - x\n",
    "f2 =  lambda x: 4 - 2 * x\n",
    "x = np.linspace(0, 2, 100)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, f1(x) , linewidth= 2)\n",
    "ax.plot(x, f2(x) , linewidth= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Rows than Columns\n",
    "\n",
    "Next, consider the case where $A$ is not a square matrix, and the number of rows exceed the number of columns ($m > n$). This is the case that applies to OLS regression in econometric analysis: the number of observations $m$ is typically much higher than the number of regressors ($n$). \n",
    "\n",
    "In this case, it is *very unlikely that a solution to $Ax = b$ exists*. To get some intuition, let $m = 3$ and $n = 2$, and let  \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}A\n",
    "=\n",
    "\\left[\n",
    "\\begin{array}{cc}\n",
    "    1 &  0 \\\\\n",
    "    0 &  1  \\\\\n",
    "    0 &  0 \n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{split}\n",
    "\\end{equation} \n",
    "Hence, the column vectors of $A$ are two of the canonical basis vectors; we therefore know that the columns are linearly independent. \n",
    "\n",
    "However, the span of $A$ contains only vectors $y \\in \\mathbb{R}^3$ such that $y_3 = 0$. In other words, the span of $A$ is a two-dimensional plane in the three-dimensional space $\\mathbb{R}^3$ (compare figure), and thus the vast majority of points in $\\mathbb{R}^3$ is not in the span of $A$. Therefore, for an arbitrary $b$, it is highly unlikely that we can find a sequence of coefficients (i.e. a vector) $x$ such that the linear combination $Ax$ gives us $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## figure in class\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may recall from linear regression, when doing OLS we do not aim to find an exact solution, but instead compute the $x$ that minimizes the residuals. Using matrix notation and the vector norm, one way to express this is to minimize\n",
    "\\begin{equation}\n",
    "    ||\\ b - Ax\\ ||\n",
    "\\end{equation}\n",
    "which is the distance between $y$ and $Ax$. This results in the *best approximation* for $x$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\hat{x} = (A'A)^{-1} A'b.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='tri'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Triangular Linear Systems\n",
    "\n",
    "For the remainder of this class, we focus on SLEs with square matrices. In order to derive the common popular approach to solving general SLEs, we first look at how to solve *triangular* SLEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward substitution\n",
    "\n",
    "Suppose $A$ is an *lower triangular* square matrix; hence the SLE has the following form:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}A x\n",
    "=\n",
    "\\left[\n",
    "\\begin{array}{ccccc}\n",
    "    a_{11} & 0 & 0 & \\cdots & 0 \\\\\n",
    "    a_{21} & a_{22} & 0 & \\cdots & 0 \\\\\n",
    "    \\vdots & \\vdots & \\vdots & & \\vdots \\\\\n",
    "    a_{n1} & a_{n2} & a_{n3} &\\cdots & a_{nn}\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    x_{1}  \\\\\n",
    "    \\vdots  \\\\\n",
    "    x_{n}\n",
    "\\end{array}\n",
    "\\right] \n",
    " = \n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    b_{1}  \\\\\n",
    "    \\vdots \\\\\n",
    "    b_{n} \n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{split}\n",
    "\\end{equation} \n",
    "\n",
    "It is easy to see that $a_{11} x_1 = b_1$, and hence\n",
    "\\begin{equation}\n",
    "    x_1 = \\frac{b_1}{a_{11}}\n",
    "\\end{equation}\n",
    "\n",
    "Second, we have $a_{21} x_1 + a_{22} x_2 = b_2$, and hence, knowing $x_1$, we can compute $x_2$ as \n",
    "\n",
    "\\begin{equation}\n",
    "    x_2 = \\frac{b_2 - a_{21}x_1}{a_{22}}\n",
    "\\end{equation}\n",
    "\n",
    "We can continue this logic all the way to $x_{n}$ (compare Miranda & Fackler, p. 8). A general formula for $x_i$ is given by:\n",
    "\n",
    "\\begin{equation}\n",
    "    x_i = \\frac{b_i - \\sum_{j = 1}^{i - 1} a_{ij}x_j}{a_{ii}}\n",
    "\\end{equation}\n",
    "\n",
    "This way of computing the elements of $x$ in a lower triangular system of equations *recursively* is called **forward-substitution**. It is straightforward to implement in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        , -0.4       , -0.08888889])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward_sub(A, b):\n",
    "    \"\"\"\n",
    "    Implements the forward-substitution algorithm to solve a lower triangular system of equations\n",
    "    \"\"\"\n",
    "    n, m = A.shape\n",
    "    \n",
    "    assert n == m, \"A must be a square matrix\"\n",
    "    \n",
    "    x = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        summ = 0\n",
    "        for j in range(i):\n",
    "            summ += A[i, j] * x[j]\n",
    "        \n",
    "        x[i] = (b[i] - summ) / A[i, i]   \n",
    "    \n",
    "    return x\n",
    "\n",
    "A = np.array([[1, 0, 0],\n",
    "              [4, 5, 0],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "b = np.array([1, 2, 3]) \n",
    "\n",
    "x = forward_sub(A, b)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward substitution\n",
    "\n",
    "If $A$ is an *upper triangular matrix*, we can use *backward-substitution*, which works analogously to forward-substitution. I leave both the derivation and numerical implementation to this week's problem set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='lufac'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LU Factorization using Gaussian Elimination\n",
    "\n",
    "Let $L$ denote a *lower triangular* square matrix:\n",
    "\n",
    "\\begin{equation}L =\n",
    "\\left[\n",
    "\\begin{array}{ccccc}\n",
    "    a_{11} & 0 & 0 & \\cdots & 0 \\\\\n",
    "    a_{21} & a_{22} & 0 & \\cdots & 0 \\\\\n",
    "    \\vdots & \\vdots & \\vdots & & \\vdots \\\\\n",
    "    a_{n1} & a_{n2} & a_{n3} &\\cdots & a_{nn}\n",
    "\\end{array}\n",
    "\\right]\\end{equation}\n",
    "\n",
    "Similarly, let $U$ denote an *upper triangular* square matrix:\n",
    "\n",
    "\\begin{equation}U =\n",
    "\\left[\n",
    "\\begin{array}{cccc}\n",
    "    a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
    "    0 & a_{22} & \\cdots & a_{2n} \\\\\n",
    "    \\vdots & \\vdots &  & \\vdots \\\\\n",
    "    0 & 0 & \\cdots & a_{nn}\n",
    "\\end{array}\n",
    "\\right]\\end{equation}\n",
    "\n",
    "Gaussian elimination is an algorithm to factor any square matrix into the form \n",
    "\n",
    "\\begin{equation}\n",
    " A = \\tilde{L}U,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\tilde{L}$ is a *permuted* lower triangular matrix (more on this below). The key idea of Gaussian elimination is that you can *subtract constant multiples of one row of a linear equation from another row without altering the solution of the linear equation*. Similarly, you can *interchange two rows of a linear solution*, again without altering the solution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Example\n",
    "\n",
    "As an example, consider a market where the inverse supply function is given by \n",
    "\\begin{align}\n",
    "    p^s = c + d q,\n",
    "\\end{align}\n",
    "and the inverse demand function is given by\n",
    "\\begin{align}\n",
    "    p^d = a - b q.\n",
    "\\end{align}\n",
    "In equilibrium, $p^d = p^d = p$, and solving for $q$ gives \n",
    "\\begin{align}\n",
    "    q = \\frac{a + c}{b - d}.\n",
    "\\end{align}\n",
    "\n",
    "Note that we can write the market in equilibrium as a system of two linear equations in two unknowns:\n",
    "\n",
    "\\begin{align}\n",
    "    p + b q &= a \\\\\n",
    "    p - d q &= c\n",
    "\\end{align}\n",
    "or\n",
    "\\begin{equation}\n",
    "\\left[\n",
    "\\begin{array}{cc}\n",
    "    1 & b \\\\\n",
    "    1 & - d \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    p \\\\\n",
    "    q \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "=\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    a \\\\\n",
    "    c \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{equation}\n",
    "\n",
    "Let \n",
    "\\begin{equation}\n",
    "A \\equiv \\left[\n",
    "\\begin{array}{cc}\n",
    "    1 & b \\\\\n",
    "    1 & - d \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{equation}\n",
    "\n",
    "and recall that $ A = IA$, where $I$ is the identity matrix:\n",
    "\n",
    "\\begin{equation}\n",
    "A = \\left[\n",
    "\\begin{array}{cc}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1 \\\\\n",
    "\\end{array}\n",
    "\\right] \\left[\n",
    "\\begin{array}{cc}\n",
    "    1 & b \\\\\n",
    "    1 & - d \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{equation}\n",
    "\n",
    "The idea of Gaussian elimination is to start with this expression and then go through each column of $A$, transforming it such that the elements below the diagonal are zero. In this simple example, there is only one step: we need to transform the first column of $A$. We can do this by subtracting $1$ times the first row from the second row, which gives us an upper triangular matrix $U$:\n",
    "\\begin{equation}\n",
    " U = \\left[\n",
    "\\begin{array}{cc}\n",
    "    1 & b \\\\\n",
    "    0 & - d - b \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{equation}\n",
    "\n",
    "In order to keep the equality above, we update the identity matrix by the coefficient $1$:\n",
    "\\begin{equation}\n",
    "A = \\left[\n",
    "\\begin{array}{cc}\n",
    "    1 & 0 \\\\\n",
    "    1 & 1 \\\\\n",
    "\\end{array}\n",
    "\\right] \\left[\n",
    "\\begin{array}{cc}\n",
    "    1 & b \\\\\n",
    "    0 & - d - b \\\\\n",
    "\\end{array}\n",
    "\\right] \\equiv LU\n",
    "\\end{equation}\n",
    "It is easy to verify that the equality still holds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a very easy example for Gaussian elimination. A more complicated example for a 3-by-3 matrix is given in the next section below. Before, let's finish the example by giving you some intuition why it is useful to write $A$ as $LU$ and hence why Gaussian elimination is useful.\n",
    "\n",
    "Going back to our system of linear equations, let's make the following substitutions:\n",
    "\n",
    "\\begin{equation}\n",
    "Ax = LUx = L(Ux) = Ly = b\n",
    "\\end{equation}\n",
    "\n",
    "As we will see, this is easy to solve. Start with $Ly = b$. In our example above:\n",
    "\n",
    "\\begin{equation}\n",
    "\\left[\n",
    "\\begin{array}{cc}\n",
    "    1 & 0 \\\\\n",
    "    1 & 1 \\\\\n",
    "\\end{array}\n",
    "\\right] \\left[\n",
    "\\begin{array}{c}\n",
    "    y_1 \\\\\n",
    "    y_2 \\\\\n",
    "\\end{array}\n",
    "\\right] = \n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    a \\\\\n",
    "    c \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{equation}\n",
    "\n",
    "From this, it is easy to see that $y_1 = a$ and\n",
    "\n",
    "\\begin{equation}\n",
    "    y_1 + y_2 = c\\ \\Rightarrow\\ y_2 = c - a.\n",
    "\\end{equation}\n",
    "\n",
    "Hence, we have a solution for $y$ above. Recall that we had defined $Ux = y$ or\n",
    "\n",
    "\\begin{equation}\n",
    " \\begin{split}\n",
    "\\left[\n",
    "\\begin{array}{cc}\n",
    "    1 & b \\\\\n",
    "    0 & - d - b \\\\\n",
    "\\end{array}\n",
    "\\right] \\left[\n",
    "\\begin{array}{c}\n",
    "    p \\\\\n",
    "    q \\\\\n",
    "\\end{array}\n",
    "\\right] = \n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    y_1 \\\\\n",
    "    y_2 \\\\\n",
    "\\end{array}\n",
    "\\right] =\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "    a \\\\\n",
    "    c - a \\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "From this, it follows that\n",
    "\n",
    "\\begin{equation}\n",
    "q  (- d - b) = c - a\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation}\n",
    "p + bq = a.\n",
    "\\end{equation}\n",
    "\n",
    "Rearranging gives the solution\n",
    "\n",
    "\\begin{equation}\n",
    "q  = \\frac{a - c}{b + d}, \\ p = a - b \\frac{a - c}{b + d}.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Elimination with Pivoting\n",
    "\n",
    "Gaussian elimination as described above can lead to inaccurate results on a computer due to roundoff errors, which we discussed in the previous lecture. The following example (cp. Miranda and Fackler, section 2.5) gives an intuition and illustrates *pivoting* as a remedy to this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## cp. classroom notes\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, roundoff errors can be a problem if the elements on the diagonal of matrix $A$ are very small. Pivoting fixes this by interchanging rows during Gaussian elimination, in order to make the diagonal elements as large as possible (in absolute values). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PA = LU Factorization\n",
    "\n",
    "The following example deals with a Gaussian elimination for a 3-by-3 matrix. Compared to the algorithm in Miranda & Fackler, p. 11 ff., here we include (partial) pivoting, and deal differently with $L$ being a permuted lower triangular matrix. The resulting algorithm is also referred to as *PA = LU factorization*. \n",
    "\n",
    "One important takeaway from this is that there multiple ways to factor a matrix into LU components, and hence multiple valid LU representations. Question 3 in this week's problem set will further illustrate this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## cp. classroom notes\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy's **scipy.linalg.lu** function implements PA = LU factorization as introduced above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.14285714  1.          0.        ]\n",
      " [ 0.57142857  0.5         1.        ]\n",
      " [ 1.          0.          0.        ]]\n",
      "[[ 7.          8.          9.        ]\n",
      " [ 0.          0.85714286  2.71428571]\n",
      " [ 0.          0.         -0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2, 4],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "pl, u = scipy.linalg.lu(A, permute_l=True)\n",
    "print(pl )\n",
    "print( u )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Numpy's **allclose** function, we can easily check whether the product $pl \\cdot u$ is identical to $A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(pl @ u, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the matrix **pl** as returned by **scipy.linalg.lu** equals, in the notation above, $P^{-1} L$, as we can easily verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_inv = np.linalg.inv([[0, 0, 1],\n",
    "              [1, 0, 0],\n",
    "              [0, 1, 0]])\n",
    "L = np.array([[ 1.        ,  0.        ,  0.        ],\n",
    "            [ 0.14285714,  1.        ,  0.        ],\n",
    "            [ 0.57142857,  0.5       ,  1.        ]\n",
    "        ]) \n",
    "\n",
    "np.allclose(P_inv @ L , pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Before moving to solving SLEs in Python, let's summarize the key insights of this section:\n",
    "1. A SLE with a lower or upper triangular matrix can be easily solved using forward or backward substitution, respectively.\n",
    "\n",
    "2. An arbitrary matrix $A$ can be factorized into $A = \\tilde{L} U$, where $U$ is an upper triangular matrix and $\\tilde{L}$ is a permuted lower triangular matrix, using Gaussian elimination. We can then use a combination of forward and backward substitution to solve the system.\n",
    "\n",
    "3. There are different ways to implement Gaussian elimination. In practice, we use $PA = LU$ factorization, which includes partial pivoting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving a system of linear equations in Python\n",
    "\n",
    "All the steps above - PA = LU factorization using Gaussian elimination, forward- and backward substitution - are implemented in one Python function, Scipy's **linalg.solve** function. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.14285714],\n",
       "       [ 7.14285714]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, c, d = 5, 0.4, 0, 0.3\n",
    "\n",
    "A = np.array([[1, b], [1, -d]])\n",
    "x = np.array([[a], [c]])\n",
    "\n",
    "scipy.linalg.solve(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.33333333e-01,   6.66666667e-01,   3.17206578e-17])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2, 4],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "b = np.array([1, 2, 3]) \n",
    "\n",
    "np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate that LU factorization is a faster way to solve a SLE for large matrices than using the inverse, we can use Numpy's **random.uniform** function to create a large ($n = 500$) square matrix $A$ and vector $b$, both with random elements (here between 0 and 5). A quick way to measure the running time of a piece of code is Jupyter notebook's **%%timeit** \"magic\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.random.uniform(0,5,(500,500))\n",
    "b = np.random.uniform(0,5,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 1: 250 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 -n1 np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 1: 52.4 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 -n1 scipy.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 1: 259 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 -n1 np.linalg.inv(A) @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='ill'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ill-conditioned Matrices\n",
    "\n",
    "A matrix $A$ is said to be *ill-conditioned* if in the SLE $Ax =b$, a small perturbation in $b$ or in $A$ induces a large change in $x$. Recall that most real numbers, when represented as floating point numbers, are approximated by DP numbers. Hence, for an ill-conditioned matrix, small roundoff errors in $b$ can lead to large errors in the computed solution vector $x$.   \n",
    "\n",
    "A notorious example of an ill-conditioned matrix is the so-called *Vandermonde* matrix:\n",
    "\n",
    "\\begin{equation}A =\n",
    "\\left[\n",
    "\\begin{array}{ccccc}\n",
    "    a_{1}^0 & a_{1}^1 & a_{1}^2 &\\cdots & a_{1}^{n-1} \\\\\n",
    "    a_{2}^0 & a_{2}^1 & a_{2}^2 &\\cdots & a_{2}^{n-1} \\\\\n",
    "    \\vdots & \\vdots &  & \\vdots \\\\\n",
    "    a_{n}^0 & a_{n}^1 & a_{n}^2 &\\cdots & a_{n}^{n-1}\n",
    "\\end{array}\n",
    "\\right]\\end{equation}\n",
    "\n",
    "For $a_j = j$ and $n = 5$, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   1   1   1   1]\n",
      " [  1   2   4   8  16]\n",
      " [  1   3   9  27  81]\n",
      " [  1   4  16  64 256]\n",
      " [  1   5  25 125 625]]\n"
     ]
    }
   ],
   "source": [
    "n =5\n",
    "A = np.array([i**j for i in range(1,n+1) for j in range(0, n)] )\n",
    "A.shape = (n, n)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the pitfalls of an ill-conditioned matrix, consider solving $Ax =b$ where $A$ is a Vandermonde matrix and $b$ is set such that the solution vector $x$ consists of only of ones. E.g. if $n = 5$, under exact arithmetic, $x = [1, 1, 1, 1, 1]'$ and so on. Below, we solve the system for different values of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n = 5, x = [ 1.  1.  1.  1.  1.]\n",
      "For n = 5, the condition number is 26169.68797063433\n",
      "--------------------------------------------------------------------\n",
      "For n = 10, x = [ 1.00000064  0.99999871  1.00000078  0.99999993  0.99999989  1.00000005\n",
      "  0.99999999  1.          1.          1.        ]\n",
      "For n = 10, the condition number is 2106245945721.575\n",
      "--------------------------------------------------------------------\n",
      "For n = 15, x = [  1.23061043e+04  -3.93051732e+04   5.31333157e+04  -4.09524104e+04\n",
      "   2.03382320e+04  -6.93956632e+03   1.69049953e+03  -2.98555551e+02\n",
      "   4.00433004e+01  -2.73635796e+00   1.25925409e+00   9.87316999e-01\n",
      "   1.00041455e+00   9.99991879e-01   1.00000007e+00]\n",
      "For n = 15, the condition number is 9.095497295485408e+20\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for n in [5, 10, 15]:\n",
    "    ## define matrix\n",
    "    A = np.array([i**j for i in range(1,n+1) for j in range(0, n)] )\n",
    "    A.shape = (n, n)\n",
    "    ## \n",
    "    b = A @ np.ones(n)\n",
    "    ## solve SLE\n",
    "    x = np.linalg.solve(A, b)\n",
    "    \n",
    "    print(\"For n = {}, x = {}\".format(n, x))\n",
    "    print(\"For n = {}, the condition number is {}\".format(n, np.linalg.cond(A)))\n",
    "    print(\"--------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, for larger $n$, the solution vector computed numerically is very different from the exact solution, and hence the approximation error is large.\n",
    "\n",
    "Above, we also compute the *condition number* $\\kappa \\ge 1$ (using Numpy's **linalg.cond** function) which is an indicator for an ill-conditioned matrix: the greater $\\kappa$, the more severe is ill-conditioning and hence the lower is the accuracy of the computed solution. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without going into further details, the intuition when a matrix in an SLE is ill-conditioned is that it is close to a singular matrix. That said, it is important to note that the size of the determinant of a matrix - which indicates whether a matrix is singular in case it is zero - is *not* a good indicator whether a matrix is ill-conditioned or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='sparse'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Matrices\n",
    "\n",
    "A matrix is called *sparse* if it contains mainly zeros. Since it would be a waste of memory and processing power to store and process a lot of zeros when doing matrix operations, most programming languages, including Python/Scipy, have special formats for sparse matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example is taken from the Scipy documentation on sparse matrices: https://docs.scipy.org/doc/scipy/reference/sparse.html#example-1. It illustrates how to define a sparse matrices in Scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "A = lil_matrix((1000, 1000))\n",
    "A[0, :100] = np.random.rand(100)\n",
    "A[1, 100:200] = A[0, :100]\n",
    "A.setdiag(np.random.rand(1000))\n",
    "\n",
    "A = A.tocsr()\n",
    "b = np.random.rand(1000)\n",
    "\n",
    "print( type(A) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving an SLE where $A$ is defined as a sparse matrix is considerably faster than when $A$ is a full matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 1: 62 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 -n1 spsolve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 1: 179 ms per loop\n"
     ]
    }
   ],
   "source": [
    "A_ = A.toarray()\n",
    "%timeit -r1 -n1  np.linalg.solve(A_, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = spsolve(A, b)\n",
    "x_ = np.linalg.solve(A_, b)\n",
    "np.allclose(x, x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, as suggested above, the matrix takes much less storage space when it is stored as a sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000112"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(A_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite these advantages of using sparse matrices, there are also downsides (cp. M&F, appendix 2B). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id ='iterative'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many important algorithms in numerical analysis, some of which we will learn about during this course, are based on  *iteration*. The basic idea of iterative methods is generate a sequence of approximations to the object of interest, in case of SLEs the solution vector $x$. Ideally, these approximations become more and more precise with an increasing number of iterations. However, it is important to emphasize that iterative methods, in contrast to direct methods like solving SLEs with LU factorization, do not yield an exact solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a very general level, iterative methods can be formalized by the following iteration rule:\n",
    "\n",
    "\\begin{equation}\n",
    "    x^{(k+1)} = g( x^{(k)} ).\n",
    "\\end{equation}\n",
    "\n",
    "$k$ here is an indicator counting the number of iterations. Hence, in words, the value for $x$ in the $k+1$-iteration is obtained by applying function $g$ on the value for $x$ in the $k$-iteration. Naturally, the functional form of $g$ depends on the problem you want analyze. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more concreteness, let us go back to the solving the SLE. Starting at $Ax = b$, first note that rearranging and adding $Qx$ on both sides, where $Q$ is also a square matrix of order $n$ gives:\n",
    "\n",
    "\\begin{equation}\n",
    "    Qx = Qx + b - Ax\\ \\Rightarrow \\ Qx = b + (Q - A)x\n",
    "\\end{equation}\n",
    "\n",
    "Multiplying both sides with the inverse of $Q$, we get:\n",
    "\n",
    "\\begin{equation}\n",
    "    x = Q^{-1} b + (I - Q^{-1} A)x\n",
    "\\end{equation}\n",
    "\n",
    "This will be our iteration rule. In other words, the function $g$ above is given by the RHS, $Q^{-1} b + (I - Q^{-1} A)x$, and hence\n",
    "\n",
    "\\begin{equation}\n",
    "    x^{(k+1)} = g( x^{(k)} ) = Q^{-1} b + (I - Q^{-1} A)x^{(k)}.\n",
    "\\end{equation}\n",
    "\n",
    "Recall that taking the inverse of a matrix can be computationally demanding, in particular for large matrices. Hence, in order for this iteration rule to be useful, we need $Q$ to be easily invertible. One way to achieve is to require $Q$ to be diagonal or triangular. This is the idea of the **Gauss-Jacobi** and **Gauss-Seidel** methods, respectively:\n",
    "- the Gauss-Jacobi method set $Q$ equal to to a diagonal matrix with the diagonal elements of $A$; \n",
    "- the Gauss-Seidel method forms $Q$ from upper triangular elements of $A$. \n",
    "\n",
    "In Python, the **diag** and **triu** functions are useful when implementing these algorithms (the former has to applied twice):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 5 0]\n",
      " [0 0 9]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2, 4],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "Q = np.diag( np.diag(A) )\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 4]\n",
      " [0 5 6]\n",
      " [0 0 9]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2, 4],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "Q = np.triu(A)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following piece of code implements the Gauss-Seidel method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gauss_seidel(A, b, x0):\n",
    "    \"\"\" \n",
    "    Implements the Gauss-Seidel method with a over-relaxation parameter\n",
    "    \"\"\"\n",
    "    eps = 1\n",
    "    tol = 1e-8\n",
    "    it = 0\n",
    "    maxit = 100\n",
    "\n",
    "    x = x0\n",
    "    Q = np.triu(A)\n",
    "    Q_inv = np.linalg.inv(Q)\n",
    "    \n",
    "    while eps > tol and it < maxit:\n",
    "        it += 1 \n",
    "        x_new = Q_inv @ b + ( np.eye(len(b)) - Q_inv @ A) @ x\n",
    "        eps = np.linalg.norm(x_new - x)\n",
    "        x = x_new\n",
    "        \n",
    "    return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.33439602e+44  -9.47028130e+42   3.80950410e+43]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2, 4],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "x0 = np.array([-0.33, 0.66, 0]) \n",
    "b = np.array([1, 2, 3]) \n",
    "\n",
    "print( gauss_seidel(A, b, x0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the Gauss-Seidel method on our example from above, we see that the algorithm does not converge, even if we choose an initial $x$ close to the exact solution (which we know in this case). This is a drawback of using iterative methods: convergence to a good approximation is no guarantueed.\n",
    "\n",
    "In the case of solving an SLE, it can be shown that we get convergence if the following condition holds:\n",
    "\n",
    "\\begin{equation}\n",
    "    || I - Q^{-1} A || < 1.\n",
    "\\end{equation}\n",
    "\n",
    "For now, we do not look at why this is a case, but just this property as a given. We can evaluate this expression for our example and find that the condition is not satisfied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.55867918347\n"
     ]
    }
   ],
   "source": [
    "print( np.linalg.norm(np.eye(len(b)) - np.linalg.inv(np.triu(A)) @ A) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To consider an example where convergence is guarantueed, *independent from the starting value for* $x$, modify $A$ by increasing the elements on the diagonal (cp. Miranda and Fackler for why this works):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60651756409485424"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[10, 2, 4],\n",
    "              [4, 15, 6],\n",
    "              [7, 8, 20]])\n",
    "\n",
    "np.linalg.norm(np.eye(len(b)) - np.linalg.inv(np.triu(A)) @ A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condition above is satisfied; applying the Gauss-Seidel algorithm finds a solution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04275093  0.08085502  0.10269517]\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([1, 1, 1]) \n",
    "b = np.array([1, 2, 3]) \n",
    "print( gauss_seidel(A, b, x0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify that this solution is found for different values for the starting value **x0**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When should you use iterative methods rather than computing an exact solution to a SLE? A rule of thumb is for large matrices, in particular if they are sparse, iterative methods may be a faster way to find $x$. For this course, all problems that involve solving a SLE will be of moderate size, hence LU factorization will do fine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
