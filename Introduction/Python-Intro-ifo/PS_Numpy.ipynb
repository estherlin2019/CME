{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python - Numpy\n",
    "## Problem Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last update: 2017-05-11 12:10:38.322662\n"
     ]
    }
   ],
   "source": [
    "# Authors: Matthias Huber (huber@ifo.de), Alex Schmitt (schmitt@ifo.de)\n",
    "\n",
    "import datetime\n",
    "print('Last update: ' + str(datetime.datetime.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "(a) Create random vector with five elements and print the average of the vector. Then, replace the maximum value by 0 and print the vector and its average again.\n",
    "\n",
    "(b) Use NumPy's **random** package to get **N** draws from a standard normal distribution (google to get the name of the corresponding function and its syntax!) and store them in a NumPy array. Find the sample average and standard deviation for **N = 10**, **N = 1000** and **N = 1000000**.\n",
    "\n",
    "(c) For the last case in question (a) with **N = 1000000**, use an index array or Numpy's **where** function to find the share of draws that is either less than -1.96 or greater than 1.96. What's your expectation what this share should be?\n",
    "\n",
    "(d) Create a two-dimensional 4-by-4 NumPy array **A** with elements from 1 to 16. A quick way to do is using Python **range** function and the **shape** method of NP arrays. Recall from linear algebra that multiplying any matrix with the identity matrix **I** just results in same matrix (i.e. $I \\cdot A = A \\cdot I = A$). Confirm this using your array **A**. What happens if you multiply **A** with an array of the same dimension that consists only of 1s?\n",
    "\n",
    "(e) Write a function **get_diag** that takes a *square* matrix of dimension **n** and returns a flat array of length **n** that contains the elements on the matrix' diagonal. The first thing the function should do is checking if the input is a square array and give an error message otherwise. You could this in many ways; one neat option is an **assert** statement (check the documentation!). Alternatively, you could use a print statement and interrupt the function with **Return None**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Consider the polynomial expression\n",
    "\\begin{equation*}\n",
    "\tp(x) = a_0 + a_1 x + a_2 x^2 + \\cdots + a_N x^N = \\sum_{n=0}^N a_n x^n,\n",
    "\\end{equation*}\n",
    "where $x$ is a scalar number.\n",
    "\n",
    "(a) Write a Python function **poly(x, coeff)** that implements $p(x)$ (i.e. evaluates the polynomial) given a point **x** and a list of coefficients **coeff** ($= a_0,...,a_N$). Use a loop with **enumerate()**.\n",
    "\n",
    "(b) Write a new function **poly_np(x, coeff)** that does the same job, but uses NumPy arrays and vectorized operations, rather than any form of Python loop. Hint: Use **np.cumprod()**.\n",
    "\n",
    "(c) Using **%time**, check how long it takes for both functions to run when **len(coeff)** = 50000 (you can use arbitrary values for the elements in **coeff**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 3\n",
    "\n",
    "Compute an approximation to $\\pi$ with the Monte Carlo method using **Numpy**. Your hints are as follows:\n",
    "- If $U$ is a bivariate uniform random variable on the unit square $(0,1)^2$, then the probability that $U$ lies in a subset $B$ of $(0,1)^2$ is equal to the area of $B$.\n",
    "- If $U_1,...,U_n$ are iid copies of $U$, then, as $n$ gets large, the fraction that fall in $B$ converges to the probability of landing in $B$\n",
    "- Recall that for a circle, $area = \\pi * radius^2$\n",
    "\n",
    "(Source: lectures.quantecon.org, An Introductory Example, Exercise 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "In this question, you are asked to write your own implementation of the *bisection method* to compute the root of a real-valued function. Of course, most programming languages already have in-built implementations (e.g. in SciPy: **scipy.optimize.bisect**}, so writing your own function may seem a bit redundant. The goal here is to give you some idea about the inner workings of many of the algorithms used in scientific computing. The bisection method, while quite simple, captures two important features of most root-finding and optimization methods: it is a *local* method and it is based on an *iterative procedure*. \n",
    "\n",
    "- Recall that a root of a real-valued function $f$ is a value $x$ in the domain of the function such that $f(x)=0$. The idea behind the bisection method is based on the *Intermediate Value Theorem*: if $f$ is continuous and defined on the interval $[a,b]$, and if $f(a)$ and $f(b)$ are distinct values, then $f$ must assume all values in between. Since we are interested in where $f$ assumes the value 0, we need $f(a)$ and $f(b)$ to have different signs.\n",
    "- The bisection method implements the following \"pseudo-code\":\n",
    "\n",
    "(i) Start with two values $a$ and $b$ such that $f(a)$ and $f(b)$ are defined and have different signs. Moreover, specify a \"tolerance level\" $tol$ which should be a very small number, e.g. 1e-8.\n",
    "\n",
    "(ii) Compute the midpoint between $a$ and $b$, $x = \\frac{a + b}{2}$. \n",
    "\n",
    "(iii) If $f(x)$ has the same sign as $f(a)$, replace the left endpoint of the interval with $x$, i.e. $a = x$.\n",
    "\n",
    "(iv) If $f(x)$ has the same sign as $f(b)$, replace the right endpoint of the interval with $x$, i.e. $b = x$.\n",
    "\n",
    "(v) Repeat from (ii) until the absolute value of $f(x)$ is less than $tol$, i.e. $|f(x)| < tol$.\n",
    "\n",
    "- Bisection is an *iterative procedure*: at the beginning of each iteration step, the interval $[a,b]$ contains a root of $f$. The interval is then divided (\"bisected\") into two subintervals of equal length. One of the two subintervals must contain the root, and hence have endpoints of different signs. This subinterval is taken as the interval $[a,b]$ used for the next iteration. This process continues until the resulting midpoint $x$ of the current interval is sufficiently close to 0.  \n",
    "- Moreover, note that bisection is a *local* method: it will not give you all the roots of a function, but only one of the roots (in case there are multiple roots) between $a$ and $b$. A corollary of this is that the outcome of bisection (and of local methods in general) is sensitive to the starting point chosen by the user, here the values for $a$ and $b$.\n",
    "\n",
    "Write a function **mybisect(f, a, b)** in Python that implements the pseudo-code above. Then, test it on the function \n",
    "\\begin{equation*}\n",
    "    f(x) = \\sin(4 (x - 1/4)) + x + x^{20} - 1,\n",
    "\\end{equation*}\n",
    "i.e. find a root of this function. Compare your result to what SciPy's in-built function returns (provided below). \n",
    "\n",
    "*Hint*: most modern programming languages have some type of **while**-loop, which will prove useful here. Moreover, in Python/NumPy, consider using the **abs()** and **np.sign()** functions.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 5\n",
    "\n",
    "In this question, we are going to go through a very simple implementation of dynamic programming in Python. If you have never heard of dynamic programming before, don't worry - just follow along the instructions. \n",
    "\n",
    "As an application, recall the standard neoclassical growth model (Ramsey model) from your Macro classes. Suppose a social planner maximizes lieftime utility of a infinitely-lived, representative household: \n",
    "\\begin{equation}\n",
    "    \\max \\sum^\\infty_{t = 0} \\beta^t u(c_t) \n",
    "\\end{equation}\n",
    "s.t. \n",
    "\\begin{equation}\n",
    "    k_{t+1} + c_t = f(k_t) + (1 - \\delta) k_t = k_t^\\alpha + (1 - \\delta) k_t. \n",
    "\\end{equation}\n",
    "In words, there is a single consumption good, which is produced using a single production factor, capital $k_t$, which is accumulated over time. $f$ denotes the production function, while $u$ denotes the utility function. To make things even more simple, assume that $u(c) = \\log(c)$ and $\\delta = 1$ (i.e. capital fully depreciates between two periods). \n",
    "\n",
    "Hence, we can write the planner's maximization problem more compactly in the following way: \n",
    "\\begin{equation}\n",
    "    \\max_{k_{t+1}} \\sum^\\infty_{t = 0} \\beta^t \\log(k_t^\\alpha - k_{t+1}). \n",
    "\\end{equation}\n",
    "This is an intertemporal optimization problem, maximizing an infinite sum. Under the particular assumptions made here, we can find an analytical solution to the problem, using a standard Lagrangian. The planner's *optimal decision rules* for investment and consumption are given by:\n",
    "\\begin{equation}\n",
    "    k_{t+1} = \\alpha \\beta k_t^\\alpha,\\ c_t = (1 - \\alpha \\beta) k_t^\\alpha.\n",
    "\\end{equation}\n",
    "In other words, in every period a constant share $\\alpha \\beta$ of output is \"saved\", while the remaining share is consumed. \n",
    "\n",
    "The goal of this question is to find the same \"policy function\" numerically. As a side note, while the analytical solution just holds for the specific assumptions made above (Cobb-Douglas production function, log utility, full depreciation), the numerical approach used below works for general functional forms and less-than-full depreciation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Start by writing two short Python function - **utility** and **prod** - that both take a single argument and implement the utility function and the production function given above. Note that they should work on both scalar values and Numpy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Next, we define a \"grid\" for the capital stock, i.e. an array of possible values that $k_t$ can take. Of course, the capital stock in this model is a *continuous* variable. However, we cannot really express continuous variables (with infinitely many values) on a computer, so we need to *discretize* them.\n",
    "\n",
    "For this, assume that the capital stock always lies between two values, **k_min** and **k_max** (In other words, if the capital stock in period 0 is between these two values, it will not go outside of the interval, assuming that the planner behaves optimally). Of course, these bounds depend on the parameter values for $\\alpha$ and $\\beta$. Set **alpha** to 0.33 and **beta** to 0.95. Then, **k_min = 0.05** and **k_max = 0.25** will do the trick. Use Numpy's **linspace** function to create an array **k_grid** with **N** values for capital between these two bounds. For now, set **N = 100**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) The key insight of dynamic programming is the *Bellman equation*. In terms of the model above, it states that the following equation must hold for any (feasible) $k_t$:\n",
    "\\begin{equation}\n",
    "    v(k_t) = \\max_{k_{t+1}} \\log(k_t^\\alpha - k_{t+1}) + \\beta v(k_{t+1})  \n",
    "\\end{equation}\n",
    "$v$ is called the *value function*. To keep the question reasonably short, we skip the intuition behind this equation. \n",
    "\n",
    "We use the idea of the Bellman equation in a simple algorithm called *value function iteration* (again, we omit the discussion why this works, just believe us:). The main steps are the following.\n",
    "1. Start with an initial guess for the value function, $v^0$. For simplicity, we're going to use $v^0(k) = 0$ for all $k$.\n",
    "2. Given your current guess $v^n$ for the value function, solve the maximization on the right hand side of the value function and call it $v^{n+1}$:\n",
    "\\begin{equation}\n",
    "    \\max_{k_{t+1}} \\log(k_t^\\alpha - k_{t+1}) + \\beta v^{n}(k_t)\\ \\rightarrow\\ v^{n + 1}(k_t)\n",
    "\\end{equation}\n",
    "3. Check if $v^{n+1}$ is sufficiently close to $v^n$ (more on this below). If not, use $v^{n + 1}$ as your new current guess and go back to 2. and repeat. If $v^{n+1} \\approx v^n$, you have found an approximation $v^* $ of the \"true\" value function, with $v^* = v^{n+1}$.\n",
    "\n",
    "The beauty of this algorithm is that it is guarantueed to converge (given that some conditions are satisfied, which they are here), i.e. *no matter your initial guess for the value function, you will always find a $v^{*}$* (and the algorithm will stop at $v^*$).\n",
    "\n",
    "The above algorithm can be implemented numerically in many different ways, some better than others. One apect that distinguishes different methods is how to represent a function $v$ numerically. Here, in the simplest possible implementation, we represent $v$ *as a (one-dimensional) numpy array* of length **N**. The $i$th element of this array will give the value function for the corresponding element of **k_grid**: **v_i =** v(**k_grid_i**). \n",
    "\n",
    "Implement step 1 of the algorithm above, i.e. define a numpy array **v0** that contains only zeros (or any arbitrary value) as the initial guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Implement step 2 of the algorithm above. That is, for each element in **k_grid**, find $x$ (a floating point number) that satisfies\n",
    "\\begin{equation}\n",
    "    \\max_{x \\in \\mathbf{kgrid}} \\log(\\mathbf{k}_i - x) + \\beta \\mathbf{v0}\n",
    "\\end{equation}\n",
    "\n",
    "One thing to note here is that we assume that our maximizer $x$ is also an element of **k_grid**. Hence, strictly speaking, we don't look for the overall optimal capital stock, but for the optimal capital stock *within the discrete set of grid points*.\n",
    "\n",
    "The easiest way to implement this maximization is to loop through **k_grid** for the *current* capital stock, compute an array of possible values using **k_grid** as the set of possible *next-period* capital stocks, and use **np.max** to find the maximum value in this array. Since **v0** consists of only zeros, it can be ignored for now. \n",
    "\n",
    "Store the result of each iteration in a numpy array **v**. Print **v** and use eyeballing (or some numpy function like **diff**) to check that the elements in **v** are strictly increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Next, we need a metric to see how close the current guess of the value function, **v**, is to the old guess, **v0**. Since we essentially compare two vectors, we can use the standard vector norm:\n",
    "\\begin{equation}\n",
    " \\epsilon = || v - v_0 || = \\sqrt{ \\sum_{i = 1}^N | (v_i - v_{0i})^2 }\n",
    "\\end{equation}\n",
    "Numpy has a function **norm** in its **linalg** package that evaluates this. Use this (or your own implementation of the vector norm) to find **eps** (a scalar), a measure of closeness between **v** and **v0**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) We can now implement the rest of the algorithm, using a **while** loop. In each iteration you should do three things:\n",
    "1. given the current guess, **v_old**, get your new guess for the value function **v** using the same maximization procedure as in question (d);\n",
    "2. measure the closeness **eps** between **v** and **v_old** using the vector norm, as in question (e);\n",
    "3. update the current guess with the new guess for the next iteration: **v_old = v**. (Hint: You may want to use a copy of **v** here).\n",
    "\n",
    "The **while** loop should run until **v** and **v_old** are reasonably close, i.e. until **eps** is almost zero (since this is an approximation, we will never get to **eps** being equal to zero!). A common \"tolerance level\" for **eps** is **tol** = 1e-8 = 0.00000001. In other words, stop the loop when **eps = tol**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) We now have the approximated value function, stored in array **v**. However, we are not done yet; what we are ultimately interested in is not the value function, but the policy rule for investment. Define a one-dimensional numpy array **k_pol** with length **N**. Then, run the **for** loop from the previous question again (only the inner **for** loop, not the outer **while** loop!), using **v** as your current guess. Instead of finding the maximum value with **np.max**, find the *position of the maximizer* using **np.argmax**. This gives you the index where the maximum value is attained. Use this index **max_ind** to fill **k_pol**, i.e. in iteration **it** of the **for** loop, **k_pol[it] = k_grid[max_ind]**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(h) Use the figure below to compare your numerical solution with the \"real\" solution. We have plotted the analytical solution (you will learn how to create graphs like this in the next lecture). If you have found **k_pol**, uncomment the last line and run the cell. You should get a second curve which is a bit wobbly, which follows the blue curve.\n",
    "\n",
    "The reason why the numerical solution is wobbly is that the quality of your approximation depends on the number of grid points. Above we have used **N = 100**, which is fairly small. Repeat the steps in questions (b), (c), (f) and (g), this time using **N = 1000** (the **while** loop will take a few seconds to finish). Now, the wobbliness should be gone, and the curves should lie almost on top of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## question (h)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(k_grid, alpha * beta * prod(k_grid), linewidth =2, label = \"Analytical PF\" )\n",
    "# ax.plot(k_grid, k_pol, linewidth =2, label = \"Numerical PF\" )\n",
    "ax.set_xlim([0.05, 0.25])\n",
    "ax.set_xlabel('Current Capital Stock')\n",
    "ax.set_ylabel('Investment')\n",
    "ax.legend(loc = \"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
